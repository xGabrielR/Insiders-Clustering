{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All In One Place Clients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Aux Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from datetime import datetime\n",
    "from re import findall, search\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.utils import (\n",
    "    MONGO_USER, \n",
    "    MONGO_PASSWORD,\n",
    "    MONGO_DB, MONGO_COLLECTION,\n",
    "    SSMS_DB, SSMS_USER, \n",
    "    SSMS_PSWD, SSMS_HOST\n",
    ")\n",
    "\n",
    "np.random.seed(123)\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = \"clustering_logs.txt\" \n",
    "\n",
    "MONTH_MAP = {\"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6, \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12}\n",
    "\n",
    "CLUSTERING_USED_COLS = ['invoice_no', 'stock_code', 'quantity', 'invoice_date', 'unit_price', 'customer_id']\n",
    "\n",
    "STRING_CON_MONGO = f\"mongodb+srv://{MONGO_USER}:{MONGO_PASSWORD}@insiderscluster.pvxqe5i.mongodb.net/?retryWrites=true&w=majority\"\n",
    "STRING_SSMS_CONNECTION = f\"mssql+pyodbc:///?odbc_connect=DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SSMS_HOST};DATABASE={SSMS_DB};UID={SSMS_USER};PWD={SSMS_PSWD}\"\n",
    "\n",
    "QUERY_SELECT_TABLE = \"\"\"\n",
    "select \n",
    "\tInvoiceNo,\n",
    "\tStockCode,\n",
    "\tCAST(Quantity AS INT)   AS Quantity,\n",
    "\tInvoiceDate,\n",
    "\tUnitPrice,\n",
    "\tCAST(CustomerID as INT) AS CustomerID\n",
    "from CLIENT_SALES\n",
    "\"\"\"\n",
    "\n",
    "def get_describes(df1, stats=True):\n",
    "    num_att = df1.select_dtypes(include=['float64', 'int64'])\n",
    "    cat_att = df1.select_dtypes(include=['object'])\n",
    "\n",
    "    if cat_att.empty:\n",
    "        m = num_att.describe().T \n",
    "        m = num_att.describe().T\n",
    "        d0 = pd.concat([num_att.apply(lambda x: x.skew()), num_att.apply(lambda x: x.kurtosis()), num_att.apply(lambda x: x.max() - x.min())], axis=1)\n",
    "        m = pd.concat([m, d0.rename(columns={0:\"skew\",1:\"kurtosis\",2:\"range\"})], axis=1)\n",
    "\n",
    "        if stats: return m\n",
    "        else: return num_att\n",
    "\n",
    "    else:\n",
    "        m = num_att.describe().T \n",
    "        m, n = num_att.describe().T, cat_att.describe().T\n",
    "        d0 = pd.concat([num_att.apply(lambda x: x.skew()), num_att.apply(lambda x: x.kurtosis()), num_att.apply(lambda x: x.max() - x.min())], axis=1)\n",
    "        m = pd.concat([m, d0.rename(columns={0:\"skew\",1:\"kurtosis\",2:\"range\"})], axis=1)\n",
    "\n",
    "        if stats: return m, n\n",
    "        else: return num_att, cat_att"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Read Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulaçõa de clusterização de 10 novos clientes vindos do SSMS e inseridos na coleção Insiders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clients_list = [12868.0, 17572.0, 14078.0, 14001.0, 12662.0, 15525.0, 14237.0, 17905.0, 15485.0, 12433.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_engine(STRING_SSMS_CONNECTION)\n",
    "con = db.connect()\n",
    "\n",
    "df1 = pd.read_sql_query(QUERY_SELECT_TABLE, con=con)\n",
    "\n",
    "df1 = df1[df1.CustomerID.isin(new_clients_list)].reset_index(drop=True)\n",
    "\n",
    "df1.columns = [' '.join(findall('([A-Z]+[^A-Z+]*)', k)).replace(' ', '_').lower() for k in df1.columns]\n",
    "\n",
    "df1 = df1[CLUSTERING_USED_COLS]\n",
    "\n",
    "con.close()\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | DATA LOADED\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | START DESCRIPTIVE STATISTICS\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Basic Pandas Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Cols: {df1.shape[1]}');\n",
    "print(f'NUmber of Rows: {df1.shape[0]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Check Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df1.invoice_date[0].split('-')[1] in MONTH_MAP.keys():\n",
    "    df1.invoice_date = pd.to_datetime(df1['invoice_date'], format='%d-%b-%y')\n",
    "\n",
    "else:\n",
    "    df1.invoice_date = pd.to_datetime(df1['invoice_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum() / len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Fillout Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df1.loc[df1.customer_id.isna(), :]\n",
    "df_not_missing = df1.loc[~df1.customer_id.isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "\n",
    "aux['customer_id'] = range(19000,19000+len(aux),1)\n",
    "\n",
    "df1 = pd.merge(df1, aux, how='left', on='invoice_no')\n",
    "\n",
    "df1['customer_id'] = df1.customer_id_x.combine_first(df1.customer_id_y)\n",
    "\n",
    "df1 = df1.drop(columns=['customer_id_x', 'customer_id_y']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)\n",
    "df1.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.customer_id = df1.customer_id.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = get_describes(df1, stats=True)\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['customer_id', 'invoice_no', 'stock_code', 'quantity', 'invoice_date', 'unit_price']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. Data Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | START DATA FILTERING\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Wrongs & Cleaning Stock Codes\n",
    "wrong_stock_code_numbers = df2[df2.stock_code.apply(lambda x: bool(search('^[a-zA-Z]+$', x)))].stock_code.unique()\n",
    "\n",
    "df2 = df2[~df2.stock_code.isin(wrong_stock_code_numbers)].reset_index(drop=True)\n",
    "df2.stock_code = df2.stock_code.str.extract('([0-9]+)')\n",
    "df2.dropna(inplace=True)\n",
    "df2.stock_code = df2.stock_code.astype(int)\n",
    "\n",
    "neg_quantity, df_ref = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "negative_quantity = df2[df2.quantity <= 0]\n",
    "negative_quantity[['customer_id','stock_code','quantity']]\n",
    "\n",
    "for i, r in negative_quantity.iterrows():\n",
    "    aux = df2[(df2.customer_id == r.customer_id)&(df2.stock_code == r.stock_code)]\n",
    "\n",
    "    aux_correct_invoices = aux[~aux.invoice_no.str.contains('C')].reset_index(drop=True)\n",
    "    \n",
    "    try:\n",
    "        row = aux_correct_invoices.iloc[0]\n",
    "\n",
    "        row['quantity'] = aux[['stock_code', 'quantity']].groupby('stock_code').sum()['quantity'].values[0]\n",
    "\n",
    "        df_ref = pd.concat([df_ref, pd.DataFrame(row).T], axis=0)\n",
    "\n",
    "    except:\n",
    "        neg_quantity = pd.concat([neg_quantity, aux], axis=0)\n",
    "\n",
    "df_ref = df_ref.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if have necessary use negative values dataframe\n",
    "display(neg_quantity.head())\n",
    "\n",
    "del neg_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows from New Concatenate\n",
    "total_rows_deleted = 0\n",
    "for i, r in df_ref.iterrows():\n",
    "    rows_to_delete = df2[(df2.stock_code == r.stock_code)&(df2.customer_id == r.customer_id)].index\n",
    "    df2 = df2[~df2.index.isin(rows_to_delete)].reset_index(drop=True)\n",
    "\n",
    "    total_rows_deleted += len(rows_to_delete)\n",
    "\n",
    "# Concat new cleaned rows\n",
    "df2 = pd.concat([df2, df_ref], axis=0)\n",
    "df2 = df2.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "del df_ref\n",
    "\n",
    "print(f\"Total Rows Deleted: {total_rows_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Unit Price & Quantity\n",
    "df2 = df2[df2.quantity >= 1].reset_index(drop=True)\n",
    "df2 = df2[df2.unit_price >= 0.04].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.quantity = df2.quantity.astype(int)\n",
    "df2.invoice_no = df2.invoice_no.astype(int)\n",
    "df2.stock_code = df2.stock_code.astype(int)\n",
    "df2.customer_id = df2.customer_id.astype(int) \n",
    "df2.unit_price  = df2.unit_price.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df2.drop(columns=['description'], inplace=True)\n",
    "except:\n",
    "    df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | START FEATURE ENGINEERING\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1\n",
    "\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reference for Correct Granularity\n",
    "df_ref = df3[['customer_id']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross Revenue ( Invoicing ) Quantity * Price\n",
    "df3['gross_revenue'] = df3['unit_price'] * df3['quantity']\n",
    "\n",
    "aux = df3[['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "\n",
    "df_ref = pd.merge(df_ref, aux, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency ( Time between the last purchases )\n",
    "aux = df3[['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index()\n",
    "\n",
    "aux['recency_days'] = (aux['invoice_date'].max() - aux['invoice_date']).dt.days\n",
    "\n",
    "df_ref = pd.merge(df_ref, aux[['customer_id', 'recency_days']], on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantity of Itens Purchases\n",
    "aux = df3[['customer_id', 'quantity']].groupby('customer_id').sum().reset_index()\\\n",
    "                                      .rename(columns={'quantity': 'qnty_itens'})\n",
    "\n",
    "df_ref = pd.merge(df_ref, aux, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Purchases\n",
    "aux = df3[['customer_id','invoice_no','invoice_date']].drop_duplicates()\\\n",
    "                                                      .groupby('customer_id')\\\n",
    "                                                      .agg(max_=('invoice_date', 'max'),\n",
    "                                                           min_=('invoice_date', 'min'),\n",
    "                                                           buys=('invoice_no', 'count'),\n",
    "                                                           days=('invoice_date', lambda x: (x.max() - x.min()).days + 1)).reset_index()\n",
    "\n",
    "# Frequency\n",
    "aux['frequency'] = aux[['buys','days']].apply(lambda x: x['buys'] / x['days'] if x['days'] != 0 else 0, axis=1)\n",
    "\n",
    "df_ref = pd.merge(df_ref, aux[['customer_id', 'frequency']], on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | START DATA PREPARATION\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df3\n",
    "\n",
    "df4 = df_ref.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Reescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in df4.columns[1:]:\n",
    "    df4[k] = df4[k].apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0. Transform Feature Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | START EMBEDDINGS CLUSTERING\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "\n",
    "X = df5.iloc[:,1:]\n",
    "X_train, y_train = X.iloc[:,1:], X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pkl.load(open('../params/random_forest_leafes.pkl', 'rb'))\n",
    "reducer = pkl.load(open('../params/umap_reducer_new.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leafs_rf = pd.DataFrame(rf.apply(X_train))\n",
    "embs = pd.DataFrame(reducer.transform(df_leafs_rf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0. Machine Learning Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pkl.load(open('../params/model.pkl', 'rb'))\n",
    "\n",
    "df_ref['cluster'] = model.predict(embs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0. Clustering Model Results Storange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [MAIN] | START DATA STORANGE\", file=open(LOGS_PATH, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df_ref.copy()\n",
    "\n",
    "df7 = df7.sort_values(by='cluster').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.cluster = df7.cluster.astype('int64')\n",
    "df7.qnty_itens = df7.qnty_itens.astype('int64')\n",
    "df7.customer_id = df7.customer_id.astype('int64')\n",
    "df7.recency_days = df7.recency_days.astype('int64')\n",
    "\n",
    "df7.frequency = df7.frequency.astype('float64')\n",
    "df7.gross_revenue = df7.gross_revenue.astype('float64')\n",
    "\n",
    "df7.columns = [k.upper() for k in df7.columns]\n",
    "\n",
    "df7['CLUSTERING_DATE'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df7.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Data Storange on Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = MongoClient(STRING_CON_MONGO)\n",
    "\n",
    "clients_collection = cli[MONGO_DB][MONGO_COLLECTION]\n",
    "\n",
    "# If \"Truncate table\"\n",
    "#cli[MONGO_DB][MONGO_COLLECTION].delete_many({})\n",
    "\n",
    "clients_collection.insert_many(\n",
    "    df7.to_dict(orient='records'),\n",
    "    ordered=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ds-em-cluster': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8718d54811d4f66c83946d26a45f65f9104e0964b6cedec698ffd999d506c85c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
